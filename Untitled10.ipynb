{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4f91a6-48d3-4643-8f50-89b6513defb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee93f27-d97b-463b-91c4-f0abc6cc185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 1: What is Logistic Regression, and how does it differ from Linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c875f-4cce-481c-8327-5ca72fcbc040",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic regression is a statistical model used to predict a **categorical outcome** (often binary, like yes/no) by estimating probabilities using the **logistic (sigmoid) function**, which outputs values between 0 and 1.\n",
    "\n",
    "It differs from linear regression in that:\n",
    "\n",
    "* **Linear regression** predicts a continuous value.\n",
    "* **Logistic regression** predicts the probability of a class, not a continuous number, and uses a nonlinear transformation (sigmoid) instead of a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376ddce-695c-46c9-a6f8-03b7897b88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 2: Explain the role of the Sigmoid function in Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5272d-8ee3-43b2-832b-1cb62c32ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "In logistic regression, the **sigmoid function** converts the linear combination of inputs (which can be any real number) into a value between **0 and 1**, representing the probability of the positive class.\n",
    "\n",
    "Its role is to:\n",
    "\n",
    "1. **Map outputs to probabilities** → Ensures predictions stay in the valid range (0–1).\n",
    "2. **Enable classification** → By applying a threshold (e.g., ≥0.5), we decide the class label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c8895-2891-421e-889f-496ab5f9cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 3: What is Regularization in Logistic Regression and why is it needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43427e1b-5cd2-4edf-92c0-ba1fc6203204",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularization in logistic regression is a technique used to **prevent overfitting** by adding a penalty term to the loss function that discourages overly complex models (large coefficient values).\n",
    "\n",
    "It’s needed because:\n",
    "\n",
    "* It **controls model complexity**, improving generalization to unseen data.\n",
    "* Helps **reduce variance** while keeping bias reasonable.\n",
    "* Common types: **L1 (Lasso)** → can shrink some coefficients to zero; **L2 (Ridge)** → shrinks coefficients but keeps them nonzero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa02df8-bbc5-46dd-854d-3cadfe52f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 4: What are some common evaluation metrics for classification models, and why are the important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc4ee6-eb68-4ccd-9607-29bbb8aa0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common evaluation metrics for classification models include:\n",
    "\n",
    "1. **Accuracy** – Proportion of correct predictions; simple but can be misleading if data is imbalanced.\n",
    "2. **Precision** – Of the predicted positives, how many are actually positive; important when false positives are costly.\n",
    "3. **Recall (Sensitivity)** – Of the actual positives, how many were correctly predicted; important when missing positives is costly.\n",
    "4. **F1-Score** – Harmonic mean of precision and recall; balances the two, useful in imbalanced datasets.\n",
    "5. **ROC-AUC** – Measures model’s ability to distinguish classes across thresholds; higher is better.\n",
    "\n",
    "They’re important because they **reveal different aspects of model performance** and help choose the right model depending on the problem’s priorities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012daa6c-afba-4990-88f5-5365b86346af",
   "metadata": {},
   "outputs": [],
   "source": [
    "5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
    "splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
    "(Use Dataset from sklearn package)\n",
    "(Include your Python code and output in the code box below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65caefaf-e9c9-4615-8eee-899f37559299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset from sklearn and convert to DataFrame\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create and train logistic regression model\n",
    "model = LogisticRegression(max_iter=10000)  # Increase iterations to ensure convergence\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd91474-f808-4580-89cd-303805a0a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "6: Write a Python program to train a Logistic Regression model using L2\n",
    "regularization (Ridge) and print the model coefficients and accuracy.\n",
    "(Use Dataset from sklearn package)\n",
    "(Include your Python code and output in the code box below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91f0cf4d-155e-4f8c-90af-0e31d15dc3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients: [[ 0.97796466  0.22675499 -0.36921764  0.02644054 -0.15485375 -0.22665079\n",
      "  -0.5186091  -0.27936438 -0.22284174 -0.03509306 -0.09377994  1.39092772\n",
      "  -0.17022173 -0.08877402 -0.02215899  0.05164999 -0.03656395 -0.03142397\n",
      "  -0.03290299  0.01227996  0.09595287 -0.51563694 -0.01698607 -0.01657517\n",
      "  -0.30594188 -0.74668265 -1.39907242 -0.50342187 -0.73505594 -0.09765041]]\n",
      "Accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression with L2 regularization (Ridge)\n",
    "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Coefficients:\", model.coef_)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55575ba-ac94-4f7e-8050-1404c6dbff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "7: Write a Python program to train a Logistic Regression model for multiclass\n",
    "classification using multi_class='ovr' and print the classification report.\n",
    "(Use Dataset from sklearn package)\n",
    "(Include your Python code and output in the code box below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f8a4ca-cfb1-4063-9c8a-4d461655fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.89      0.94         9\n",
      "   virginica       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load Iris dataset\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression with One-vs-Rest strategy\n",
    "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707a877-322a-41bc-8425-bb6317c54e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
    "hyperparameters for Logistic Regression and print the best parameters and validation\n",
    "accuracy.\n",
    "(Use Dataset from sklearn package)\n",
    "(Include your Python code and output in the code box below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385ba37a-84e5-48e6-b773-e217a721f25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'penalty': 'l1'}\n",
      "Best Cross-Validation Accuracy: 0.9670\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=10000, solver='liblinear')\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f43aad-6872-45de-98d3-ef6b086f993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 9: Write a Python program to standardize the features before training Logistic\n",
    "Regression and compare the model's accuracy with and without scaling.\n",
    "(Use Dataset from sklearn package)\n",
    "(Include your Python code and output in the code box below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc12fa49-97bb-4085-9b14-2651dd2632d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 0.9561\n",
      "Accuracy with scaling: 0.9737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression without scaling\n",
    "model_no_scale = LogisticRegression(max_iter=10000)\n",
    "model_no_scale.fit(X_train, y_train)\n",
    "y_pred_no_scale = model_no_scale.predict(X_test)\n",
    "acc_no_scale = accuracy_score(y_test, y_pred_no_scale)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression with scaling\n",
    "model_scale = LogisticRegression(max_iter=10000)\n",
    "model_scale.fit(X_train_scaled, y_train)\n",
    "y_pred_scale = model_scale.predict(X_test_scaled)\n",
    "acc_scale = accuracy_score(y_test, y_pred_scale)\n",
    "\n",
    "# Results\n",
    "print(f\"Accuracy without scaling: {acc_no_scale:.4f}\")\n",
    "print(f\"Accuracy with scaling: {acc_scale:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d719b0-ce46-428e-abcc-c016cb0f03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 10: Imagine you are working at an e-commerce company that wants to\n",
    "predict which customers will respond to a marketing campaign. Given an imbalanced\n",
    "dataset (only 5% of customers respond), describe the approach you’d take to build a\n",
    "Logistic Regression model — including data handling, feature scaling, balancing\n",
    "classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
    "use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55454c3-53da-40a8-b290-7c699c4a9c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
